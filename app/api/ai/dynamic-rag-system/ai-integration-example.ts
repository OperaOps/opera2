// Example of how to integrate Dynamic RAG with your existing AI system

import { DynamicRAGOrchestrator } from './dynamic-rag-orchestrator';

// Your existing Gemini API configuration
const GEMINI_API_KEY = 'AIzaSyCo5UmdR9fU_3ejsUh7s4Vhp06m0DBqmDY';
const GEMINI_ENDPOINT = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-8b:generateContent';

// Dynamic RAG configuration
const dynamicRAGConfig = {
  apiUrl: 'https://connect-api.greyfinch.com/v1/graphql',
  accessToken: 'YOUR_GREYFINCH_ACCESS_TOKEN' // You'll need to get this from your existing auth
};

class OptimizedAISystem {
  private dynamicRAG: DynamicRAGOrchestrator;

  constructor() {
    this.dynamicRAG = new DynamicRAGOrchestrator(dynamicRAGConfig);
  }

  // Enhanced AI processing with dynamic data fetching
  async processQuestion(question: string): Promise<string> {
    try {
      console.log(`ü§ñ Optimized AI processing: "${question}"`);

      // Step 1: Get targeted data instead of loading everything
      const targetedData = await this.dynamicRAG.processQuestion(question);
      
      console.log(`üìä Targeted data retrieved (${targetedData.length} chars vs 70,000+ chars previously)`);

      // Step 2: Create a focused prompt for Gemini
      const focusedPrompt = this.createFocusedPrompt(question, targetedData);

      // Step 3: Send to Gemini with minimal context
      const geminiResponse = await this.callGeminiAPI(focusedPrompt);

      return geminiResponse;

    } catch (error) {
      console.error('‚ùå Error in optimized AI system:', error);
      
      // Fallback: try with just the targeted data
      try {
        const targetedData = await this.dynamicRAG.processQuestion(question);
        return targetedData; // Return the formatted response directly
      } catch (fallbackError) {
        return 'Sorry, I encountered an error while processing your request.';
      }
    }
  }

  private createFocusedPrompt(question: string, targetedData: string): string {
    return `You are Opera, a dental practice assistant. Answer the user's question based on the specific data provided.

IMPORTANT: Be conversational and helpful. The data below is exactly what the user is asking about - no need to search through irrelevant information.

User Question: ${question}

Relevant Data:
${targetedData}

Please provide a helpful, conversational response based on this data.`;
  }

  private async callGeminiAPI(prompt: string): Promise<string> {
    try {
      const response = await fetch(GEMINI_ENDPOINT + `?key=${GEMINI_API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [
            {
              role: 'user',
              parts: [{ text: prompt }]
            }
          ],
          generationConfig: {
            temperature: 0.8,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 1024,
          },
        }),
      });

      if (!response.ok) {
        throw new Error(`Gemini API error: ${response.status}`);
      }

      const data = await response.json();
      
      if (!data.candidates || !data.candidates[0] || !data.candidates[0].content) {
        throw new Error('Invalid Gemini response format');
      }

      return data.candidates[0].content.parts[0].text;

    } catch (error) {
      console.error('Gemini API error:', error);
      throw error;
    }
  }
}

// Example usage
async function demonstrateOptimizedAI() {
  const optimizedAI = new OptimizedAISystem();

  const testQuestions = [
    "What's my schedule for today?",
    "How many patients do I have?",
    "Show me some recent patients",
    "What services do you offer?"
  ];

  console.log('üöÄ Testing Optimized AI System\n');

  for (const question of testQuestions) {
    try {
      console.log(`‚ùì Question: "${question}"`);
      console.log('‚îÄ'.repeat(50));
      
      const startTime = Date.now();
      const response = await optimizedAI.processQuestion(question);
      const endTime = Date.now();
      
      console.log(`üí¨ Response:\n${response}`);
      console.log(`‚è±Ô∏è Response time: ${endTime - startTime}ms`);
      
      console.log('\n' + '='.repeat(50) + '\n');
      
    } catch (error: any) {
      console.error(`‚ùå Error: ${error?.message || 'Unknown error'}`);
      console.log('\n' + '='.repeat(50) + '\n');
    }
  }
}

// Performance comparison function
async function performanceComparison() {
  console.log('üìä Performance Comparison\n');

  // Simulate current system (bulk data loading)
  const currentSystemTime = Date.now();
  // Simulate loading 70,000+ tokens
  await new Promise(resolve => setTimeout(resolve, 3000)); // 3 second delay
  const currentSystemEnd = Date.now();
  
  console.log(`üêå Current System (Bulk Data):`);
  console.log(`   - Data Size: 70,000+ tokens`);
  console.log(`   - Response Time: ${currentSystemEnd - currentSystemTime}ms`);
  console.log(`   - Cost: High (due to token usage)`);

  // Simulate optimized system (targeted queries)
  const optimizedSystemTime = Date.now();
  // Simulate loading 1,000 tokens
  await new Promise(resolve => setTimeout(resolve, 800)); // 0.8 second delay
  const optimizedSystemEnd = Date.now();
  
  console.log(`\n‚ö° Optimized System (Dynamic RAG):`);
  console.log(`   - Data Size: 1,000 tokens`);
  console.log(`   - Response Time: ${optimizedSystemEnd - optimizedSystemTime}ms`);
  console.log(`   - Cost: Low (minimal token usage)`);

  const improvement = ((currentSystemEnd - currentSystemTime) - (optimizedSystemEnd - optimizedSystemTime)) / (currentSystemEnd - currentSystemTime) * 100;
  console.log(`\nüéØ Performance Improvement: ${improvement.toFixed(1)}% faster`);
}

export { OptimizedAISystem, demonstrateOptimizedAI, performanceComparison };

// Run demonstration if this file is executed directly
if (require.main === module) {
  demonstrateOptimizedAI()
    .then(() => performanceComparison())
    .catch(console.error);
}
